{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Production and Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Authors: Ra Inta*\n",
    "\n",
    "*Copyright 2019, BH Analytics, LLC*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The purpose of this section is to provide an introduction to applying your Python code in a production environment, and deploying and maintaining this code. There are currently many options to achieve these goals; they tend to be very specific towards your particular application. We cover here only a brief overview on this vast topic.\n",
    "\n",
    "In particular, we will cover:\n",
    "\n",
    " *  Packaging scripts\n",
    " *  Automation\n",
    " *  Containerization and Docker\n",
    " \n",
    "This will provide illumination into the process of how Python imports modules, the differences between a _module_, _package_ and a _library_ and how to automate your Python code. Finally, we will cover the concept of containerization, using Docker, for rapid deployment of applications. \n",
    " \n",
    "One important note: **we do not cover the security aspects of your deployments**. These are also very dependent on your application and development/deployment environment. Please consult your local security team for best practices regarding this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packaging scripts\n",
    "\n",
    "So far we have been leveraging libraries from the vast eco-system Python has to offer. After a possible installation process, we make sure we `import` these libraries before using them, and then everything seems to (mostly) 'just work'. \n",
    "\n",
    "But _how_ exactly does this work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modules, packages and libraries\n",
    "\n",
    "\n",
    "Let's take a step back to consider this process. \n",
    "\n",
    "Take the widely-used `os` library. How does Python know how/where to retrieve this library?\n",
    "\n",
    "If we import it, we can query its `__file__` attribute: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ra/anaconda3/lib/python3.7/os.py'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.__file__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the location of the Python script containing the code for the `os` module. Note the filename has the _exact_ name as the module we imported.\n",
    "\n",
    "If we examine a random section of `os.py`, _e.g._ the `makedirs` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%less /home/ra/anaconda3/lib/python3.7/os.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makedirs(name, mode=0o777, exist_ok=False):\n",
    "    \"\"\"makedirs(name [, mode=0o777][, exist_ok=False])\n",
    "    Super-mkdir; create a leaf directory and all intermediate ones.  Works like\n",
    "    mkdir, except that any intermediate path segment (not just the rightmost)\n",
    "    will be created if it does not exist. If the target directory already\n",
    "    exists, raise an OSError if exist_ok is False. Otherwise no exception is\n",
    "    raised.  This is recursive.\n",
    "    \"\"\"\n",
    "    head, tail = path.split(name)\n",
    "    if not tail:\n",
    "        head, tail = path.split(head)\n",
    "    if head and tail and not path.exists(head):\n",
    "        try:\n",
    "            makedirs(head, mode, exist_ok)\n",
    "        except FileExistsError:\n",
    "            # Defeats race condition when another thread created the path\n",
    "            pass\n",
    "        cdir = curdir\n",
    "        if isinstance(tail, bytes):\n",
    "            cdir = bytes(curdir, 'ASCII')\n",
    "        if tail == cdir:           # xxx/newdir/. exists if xxx/newdir exists\n",
    "            return\n",
    "    try:\n",
    "        mkdir(name, mode)\n",
    "    except OSError:\n",
    "        # Cannot rely on checking for EEXIST, since the operating system\n",
    "        # could give priority to other errors like EACCES or EROFS\n",
    "        if not exist_ok or not path.isdir(name):\n",
    "            raise "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see it looks like any other Python code.\n",
    "\n",
    "(**Note:** You may be aware that most of Python itself is written in Python and the C language. The latter is for improved performance, but it makes it more difficult to read the original code. Much of the scientific stack, including NumPy and pandas, is written in C)\n",
    "\n",
    "How did Python know where to look for this module? \n",
    "\n",
    "First it looks in your current working directory (`os.getcwd()`). \n",
    "\n",
    "If the module you are trying to import is not found there, then it refers to the environment variable `PYTHONPATH`. This is dependent on your operating system (and is a likely source of nightmares and PTSD for anyone who has had to maintain several versions of Python on the same system!) `PYTHONPATH` holds a list of directories in which to look for the file associated with the module in question. \n",
    "\n",
    "Finally, if it is still not found, Python will finally look in the default location of the installation binary/executable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `from` statement looks for a function or class definition in the module, and imports only this. \n",
    "\n",
    "Taking the `os` example, we already know what the `makedirs` function looks like: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function makedirs in module os:\n",
      "\n",
      "makedirs(name, mode=511, exist_ok=False)\n",
      "    makedirs(name [, mode=0o777][, exist_ok=False])\n",
      "    \n",
      "    Super-mkdir; create a leaf directory and all intermediate ones.  Works like\n",
      "    mkdir, except that any intermediate path segment (not just the rightmost)\n",
      "    will be created if it does not exist. If the target directory already\n",
      "    exists, raise an OSError if exist_ok is False. Otherwise no exception is\n",
      "    raised.  This is recursive.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from os import makedirs \n",
    "\n",
    "help(makedirs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This single-file-per-module approach is fine for relatively simple projects. However a single file may become unweildy for large, complex applications.  It can make more sense to divide the project according to specific purposes. But what if we wish to retain the convenience of a single `import` statement? This is the concept of a _package_.\n",
    "\n",
    "A package is a directory of Python modules. If we query, say, the pandas package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.24.2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ra/anaconda3/lib/python3.7/site-packages/pandas/__init__.py'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__file__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of the `__init__.py` (if spoken aloud, this may be abbreviated to \"dunder init\"; \"dunder\" meaning here \"double underscore\") file is to co-ordinate the project, telling the import function where to access each module. It often contains shortened aliases to abstract away some of the complexities of the project organization.\n",
    "\n",
    "Continuing with the pandas example, let's say we want to read the code for `pd.read_csv()`. \n",
    "\n",
    "Take the following excerpt from the `__init__.py` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.io.api import *  # Line 42 from this version of pandas (see above). \n",
    "\n",
    "# Note the star import---this is one of the few justified uses of this syntax. Do not do this for most end-user applications!  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a reference to an import from the pandas I/O module, `pandas/io/api.py`. \n",
    "\n",
    "From there, we're told:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.io.parsers import read_csv, read_fwf, read_table  # Line 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And in `pandas/io/parsers.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    " read_csv = _make_parser_function('read_csv', default_sep=',')   # Line 709\n",
    "\n",
    " #Where:\n",
    "\n",
    " def _make_parser_function(name, default_sep=','):    # Line 528\n",
    "     pass\n",
    "     # prepare read_table deprecation\n",
    "     if name == \"read_table\":\n",
    "         sep = False\n",
    "     else:\n",
    "         sep = default_sep\n",
    "     def parser_f(filepath_or_buffer,\n",
    "                  sep=sep,\n",
    "                  delimiter=None,\n",
    "                  # Column and Index Locations and Names\n",
    "                  header='infer',\n",
    "                  names=None,\n",
    "                  index_col=None,\n",
    "                  usecols=None,\n",
    "                  squeeze=False,\n",
    "                  prefix=None,\n",
    "                  mangle_dupe_cols=True):\n",
    "        pass \n",
    "                  #etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence the pandas package is organized thus:\n",
    "\n",
    "    pandas/__init__.py\n",
    "\n",
    "        core/__init__.py\n",
    "\n",
    "        io/__init__.py\n",
    "          api.py\n",
    "          parsers.py\n",
    "    etc.\n",
    "\n",
    "So, in summary: to find `pd.read_csv()`, the interpreter first went to `pandas/__init__.py`, which told it to look in `pandas/io/api.py`, which then said the function it was looking for was really in `pandas/io/parsers.py`. Except, `read_csv()` turns out to be a particular application of the `_make_parser()` function. Phew! \n",
    "\n",
    "Although it took a while to trace this back, this way of organizing projects is particularly useful for two reasons:\n",
    " 1.  The developers can divide the project into distinct folders/sub-projects (and likely be able to divide labor accordingly); and\n",
    " 1.  All of this complexity is abstracted away from the end-user.\n",
    " \n",
    "Would you have initially thought there was this much complexity when you called `pd.read_csv()`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package distribution\n",
    "\n",
    "You can create your own packages by constructing a directory structure similarly to that shown here. Once your internal workflow has been codified in this way, it is likely to be a productivity multiplier. Your colleagues don't have to 'reinvent the wheel' and can potentially contribute and improve your project very naturally.\n",
    "\n",
    "But how do you share this hard work? \n",
    "\n",
    "There are many avenues for distribution of Python packages. Assuming you adhere to a system of version control, such as `git`, `svn` or `mercurial` (this could be a whole other module!), you may simply share the code repository (or 'repo' in the modern slang) via internal servers. A more scalable and distributed system is to host your repos online. This can be private or public. Popular avenues for this are `GitHub` (https://github.com/), `GitLab` (https://gitlab.com) or `BitBucket` (https://bitbucket.org/). \n",
    "\n",
    "Of course, you most likely didn't install many of your favorite Python libraries from any of these platforms. Most of _these_ are hosted on the Python Packaging Index, PyPI:\n",
    "\n",
    "https://pypi.org/\n",
    "\n",
    "This is a more 'official' set of repos, where there are a few more conditions in order to be hosted, including a properly formatted `setup.py` and a license type for your repository. \n",
    "\n",
    "If you installed a library using `pip` or `easy_install`, then you accessed PyPI. If you installed via an Anaconda distribution, they did all this for you! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's a Python library?\n",
    "You may see references to a Python _library_. There is no formal definition for this; it essentially refers to a package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automation\n",
    "One of the biggest advantages of using a scripting language such as Python is its capacity to automate tasks. In other words, to periodically execute instructions with little or no human intervention.\n",
    "\n",
    "In fact, there is a highly popular book called \"Automate the Boring Stuff with Python: practical programming for total beginners,\" by Al Sweigart. It is freely available, or for purchase, at https://automatetheboringstuff.com . \n",
    "\n",
    "Automation leads to productivity gains by freeing up valuable developers, and also potentially opens the door for scaling tasks. A single humans' time and cognitive half-life is finite; however, once you can run a simple script, there's often little stopping you and others from running frequently. This is doubly true for 'headless' devices, _i.e._ computing systems that do not normally function with much interactive elements such as a screen. This is the case for the majority of IoT (Internet of Things) devices.\n",
    "\n",
    "Hence one of the largest productivity gains you are likely to see in your work environment is acheiving automation of your work tasks!\n",
    "\n",
    "There are a number of different means to automate Python scripts in particular. Each requires a _scheduler_. \n",
    "\n",
    "Perhaps the simplest approach is to use the scheduler built into the operating system you have your code installed on. At least 2/3 of modern web servers run Linux, [as does every single supercomputer on the TOP500 list](https://top500.org/). We will look at how to automate a Python script to run every two minutes on a Linux/MacOS system, using the `cron` utility. \n",
    "\n",
    "On Windows, there is the Windows Task Scheduler to perform an equivalent task (although you will need to create an associated BAT file first; a DOS batch file used to execute commands within Windows. These are commands you would type into the command prompt). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will cover how to apply `cron` jobs in particular in class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Containerization and Docker\n",
    "\n",
    "In the above section, we saw how to automate the execution of a Python script. \n",
    "\n",
    "What if we wanted to port this application so that it executed, for example, remotely, rather than on your personal computer, or an IoT device. Isn't this what a server is for?\n",
    "\n",
    "However, maintaining your own server can be time-consuming and reduces portability of your applications and code. Someone (the sysadmin) is obliged to keep whatever operating system updated, and the power and connectivity needs to be maintained. \n",
    "\n",
    "One solution to this is to deploy a virtual machine (VM), enabling the developer to distribute, and potentially scale, their application. Although a more portable solution than supporting your own server farm, you still have to maintain an operating system and all the associated overhead, even though the physical is virtualized.\n",
    "\n",
    "This is where the concept of _containerization_ comes in. A _container_ is a standardized unit supplied with just the right resources the software needs to run. This standardized interface encourages portable and scalable code, allowing the developer to rapidly deploy an application.\n",
    "\n",
    "Conceptually, this is an exension to the virtualization process leading to a VM, but applying to the operating system itself. This can lead to performance improvements because of the decreased overheads.\n",
    "\n",
    "In particular, Docker is effectively an operating system for these containers. Like Python it is widely used, and has been around since 2013, so there is a rich eco-system surrounding the framework.\n",
    "\n",
    "Docker is designed to be lightweight and secure (although there are a number of important security considerations).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Why use Docker\n",
    "\n",
    "Using Docker lets you ship code faster, standardize application operations, seamlessly move code, and save money by improving resource utilization. With Docker, you get a single object that can reliably run anywhere. Docker's simple and straightforward syntax gives you full control. Wide adoption means there's a robust ecosystem of tools and off-the-shelf applications that are ready to use with Docker.\n",
    "100x100_benefit_deployment1\n",
    "Ship More Software Faster\n",
    "\n",
    "Docker users on average ship software 7x more frequently than non-Docker users. Docker enables you to ship isolated services as often as needed.\n",
    "100x100_benefit_tools\n",
    "Standardize Operations\n",
    "\n",
    "Small containerized applications make it easy to deploy, identify issues, and roll back for remediation.\n",
    "100x100_benefit_migration\n",
    "Seamlessly Move\n",
    "\n",
    "Docker-based applications can be seamlessly moved from local development machines to production deployments on AWS.\n",
    "100x100_benefit_lowcost-affordable\n",
    "Save Money\n",
    "\n",
    "Docker containers make it easier to run more code on each server, improving your utilization and saving you money.\n",
    "\n",
    "\n",
    "\n",
    "When to use Docker\n",
    "\n",
    "You can use Docker containers as a core building block creating modern applications and platforms. Docker makes it easy to build and run distributed microservices architecures, deploy your code with standardized continuous integration and delivery pipelines, build highly-scalable data processing systems, and create fully-managed platforms for your developers.\n",
    "100x100_benefit_ccontainers\n",
    "Microservices\n",
    "\n",
    "Build and scale distributed application architectures by taking advantage of standardized code deployments using Docker containers.\n",
    "100x100_benefit_delivery\n",
    "Continuous Integration & Delivery\n",
    "\n",
    "Accelerate application delivery by standardizing environments and removing conflicts between language stacks and versions.\n",
    "AWS_Benefit Icon_AutomatedOperations\n",
    "Data Processing\n",
    "\n",
    "Provide big data processing as a service. Package data and analytics packages into portable containers that can be executed by non-technical users.\n",
    "100x100_benefit_get-started-2\n",
    "Containers as a Service\n",
    "\n",
    "Build and ship distributed applications with content and infrastructure that is IT-managed and secured.\n",
    "\n",
    "\n",
    "\n",
    "Q: What is the difference between Docker Swarm, Kubernetes, and Amazon ECS?\n",
    "\n",
    "When you want to run lots of Docker containers, orchestration tools like Docker Swarm, Kubernetes, and Amazon Elastic Container Service (ECS) make it possible to start, stop, and monitor thousands (or millions) of containers. \n",
    "\n",
    "Docker Swarm is container orchestration software made by Docker that you run and manage yourself. Kubernetes is a popular open source, community maintained container orchestration software that you run and manage yourself. Amazon EKS makes it easier to run Kubernetes on AWS by providing managing the Kubernetes control plane for your containers. Amazon ECS is a fully managed AWS service that makes it easy to run containers on AWS with deep integrations to AWS services such as VPC, load balancing, service discovery, and IAM roles.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing Docker\n",
    "\n",
    "\n",
    " Install necessary certificates to download Docker images securely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "sudo apt-get update\n",
    "sudo apt-get install -y apt-transport-https ca-certificates wget software-properties-common"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Get the cryptographic (GPG) key for associated with Docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "wget https://download.docker.com/linux/debian/gpg\n",
    "sudo apt-key add gpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the official Docker repo to the packages searched by apt-get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo \"deb [arch=amd64] https://download.docker.com/linux/debian $(lsb_release -cs) stable\" | sudo tee -a /etc/apt/sources.list.d/docker.list\n",
    "\n",
    "sudo apt-get update\n",
    "\n",
    "sudo apt-cache policy docker-ce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ra  sudo apt-cache policy docker-ce\n",
    "\n",
    "docker-ce:\n",
    "\n",
    "Installed: 5:19.03.1~3-0~debian-stretch\n",
    "\n",
    "Candidate: 5:19.03.1~3-0~debian-stretch\n",
    "\n",
    "Version table:\n",
    "\n",
    "5:19.03.1~3-0~debian-stretch 500\n",
    "\n",
    "500 https://download.docker.com/linux/debian stretch/stable amd64 Packages\n",
    "\n",
    "100 /var/lib/dpkg/status\n",
    "\n",
    "5:19.03.0~3-0~debian-stretch 500\n",
    "\n",
    "500 https://download.docker.com/linux/debian stretch/stable amd64 Packages\n",
    "\n",
    "5:18.09.8~3-0~debian-stretch 500\n",
    "\n",
    "500 https://download.docker.com/linux/debian stretch/stable amd64 Packages\n",
    "\n",
    "5:18.09.7~3-0~debian-stretch 500\n",
    "\n",
    "500 https://download.docker.com/linux/debian stretch/stable amd64 Packages\n",
    "\n",
    "5:18.09.6~3-0~debian-stretch 500\n",
    "\n",
    "500 https://download.docker.com/linux/debian stretch/stable amd64 Packages\n",
    "\n",
    "5:18.09.5~3-0~debian-stretch 500\n",
    "\n",
    "500 https://download.docker.com/linux/debian stretch/stable amd64 Packages\n",
    "\n",
    "5:18.09.4~3-0~debian-stretch 500\n",
    "\n",
    "500 https://download.docker.com/linux/debian stretch/stable amd64 Packages \n",
    "\n",
    "5:18.09.3~3-0~debian-stretch 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "sudo apt-get -y install docker-ce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Managing Docker services\n",
    "\n",
    "start Docker service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "sudo systemctl start docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop Docker service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "sudo systemctl stop docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart Docker service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "sudo systemctl restart docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Docker service status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "sudo systemctl status docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ra  sudo systemctl status docker\n",
    "\n",
    "● docker.service - Docker Application Container Engine\n",
    "\n",
    "   Loaded: loaded (/lib/systemd/system/docker.service; enabled; vendor preset: enabled)\n",
    "\n",
    "   Active: active (running) since Wed 2019-07-31 19:53:34 CDT; 40min ago\n",
    "\n",
    "     Docs: https://docs.docker.com\n",
    "\n",
    " Main PID: 833 (dockerd)\n",
    "\n",
    "    Tasks: 9\n",
    "\n",
    "   Memory: 124.4M\n",
    "\n",
    "      CPU: 737ms\n",
    "\n",
    "   CGroup: /system.slice/docker.service\n",
    "\n",
    "           └─833 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock\n",
    "\n",
    "\n",
    "\n",
    "Jul 31 19:53:31 carter dockerd[833]: time=\"2019-07-31T19:53:31.401088436-05:00\" level=warning msg=\"Your kernel does not support swap memory limit\"\n",
    "\n",
    "Jul 31 19:53:31 carter dockerd[833]: time=\"2019-07-31T19:53:31.401544895-05:00\" level=warning msg=\"Your kernel does not support cgroup rt period\"\n",
    "\n",
    "Jul 31 19:53:31 carter dockerd[833]: time=\"2019-07-31T19:53:31.401840993-05:00\" level=warning msg=\"Your kernel does not support cgroup rt runtime\"\n",
    "\n",
    "Jul 31 19:53:31 carter dockerd[833]: time=\"2019-07-31T19:53:31.402205417-05:00\" level=info msg=\"Loading containers: start.\"\n",
    "\n",
    "Jul 31 19:53:33 carter dockerd[833]: time=\"2019-07-31T19:53:33.871573710-05:00\" level=info msg=\"Default bridge (docker0) is assigned with an IP address 172.17.0.0/16. Daemon\n",
    "\n",
    "Jul 31 19:53:33 carter dockerd[833]: time=\"2019-07-31T19:53:33.983973375-05:00\" level=info msg=\"Loading containers: done.\"                                                  #Jul 31 19:53:34 carter dockerd[833]: time=\"2019-07-31T19:53:34.465936142-05:00\" level=info msg=\"Docker daemon\" commit=74b1e89 graphdriver(s)=overlay2 version=19.03.1\n",
    "\n",
    "Jul 31 19:53:34 carter dockerd[833]: time=\"2019-07-31T19:53:34.481634518-05:00\" level=info msg=\"Daemon has completed initialization\"\n",
    "\n",
    "Jul 31 19:53:34 carter systemd[1]: Started Docker Application Container Engine.\n",
    "\n",
    "Jul 31 19:53:34 carter dockerd[833]: time=\"2019-07-31T19:53:34.566843704-05:00\" level=info msg=\"API listen on /var/run/docker.sock\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autostart Docker upon reboot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "sudo systemctl enable docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the nice default hello-world image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "sudo docker run hello-world"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ra  sudo docker run hello-world\n",
    "\n",
    "Hello from Docker!\n",
    "This message shows that your installation appears to be working correctly.\n",
    "\n",
    "To generate this message, Docker took the following steps:\n",
    " 1. The Docker client contacted the Docker daemon.\n",
    " 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub.\n",
    "    (amd64)\n",
    " 3. The Docker daemon created a new container from that image which runs the\n",
    "    executable that produces the output you are currently reading.\n",
    " 4. The Docker daemon streamed that output to the Docker client, which sent it\n",
    "    to your terminal.\n",
    "\n",
    "To try something more ambitious, you can run an Ubuntu container with:\n",
    " $ docker run -it ubuntu bash\n",
    "\n",
    "Share images, automate workflows, and more with a free Docker ID:\n",
    " https://hub.docker.com/\n",
    "\n",
    "For more examples and ideas, visit:\n",
    " https://docs.docker.com/get-started/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check your installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "docker --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Docker version 19.03.1, build 74b1e89"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get information about your Docker image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ra  docker info\n",
    "\n",
    "Client:\n",
    "\n",
    " Debug Mode: false\n",
    "\n",
    "\n",
    "\n",
    "Server:\n",
    "\n",
    " Containers: 3\n",
    "\n",
    "  Running: 0\n",
    "\n",
    "  Paused: 0\n",
    "\n",
    "  Stopped: 3\n",
    "\n",
    " Images: 1\n",
    "\n",
    " Server Version: 19.03.1\n",
    "\n",
    " Storage Driver: overlay2\n",
    "\n",
    "  Backing Filesystem: extfs\n",
    "\n",
    "  Supports d_type: true\n",
    "\n",
    "  Native Overlay Diff: true\n",
    "\n",
    " Logging Driver: json-file\n",
    "\n",
    " Cgroup Driver: cgroupfs\n",
    "\n",
    " Plugins:\n",
    "\n",
    "  Volume: local\n",
    "\n",
    "  Network: bridge host ipvlan macvlan null overlay\n",
    "\n",
    "  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog\n",
    "\n",
    " Swarm: inactive\n",
    "\n",
    " Runtimes: runc\n",
    "\n",
    " Default Runtime: runc\n",
    "\n",
    " Init Binary: docker-init\n",
    "\n",
    " containerd version: 894b81a4b802e4eb2a91d1ce216b8817763c29fb\n",
    "\n",
    " runc version: 425e105d5a03fabd737a126ad93d62a9eeede87f\n",
    "\n",
    " init version: fec3683\n",
    "\n",
    " Security Options:\n",
    "\n",
    "  seccomp\n",
    "\n",
    "   Profile: default\n",
    "\n",
    " Kernel Version: 4.9.0-8-amd64\n",
    "\n",
    " Operating System: Debian GNU/Linux 9 (stretch)\n",
    "\n",
    " OSType: linux\n",
    "\n",
    " Architecture: x86_64\n",
    "\n",
    " CPUs: 1\n",
    "\n",
    " Total Memory: 7.801GiB                                                                                                                                                     # Name: carter\n",
    "\n",
    " ID: S47H:35SR:TDEM:VJCN:ZKQV:RIBH:VIHK:GQ6L:UUEI:CSBD:O7OE:IM3E                                                                                                            # Docker Root Dir: /var/lib/docker\n",
    "\n",
    " Debug Mode: false\n",
    "\n",
    " Registry: https://index.docker.io/v1/ \n",
    "\n",
    " Labels:\n",
    "\n",
    " Experimental: false\n",
    "\n",
    " Insecure Registries:\n",
    "\n",
    "  127.0.0.0/8\n",
    "\n",
    " Live Restore Enabled: false\n",
    "\n",
    "\n",
    "\n",
    "WARNING: No swap limit support\n",
    "\n",
    " ra  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List all your current Docker images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker image ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ra  docker image ls\n",
    "\n",
    "REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\n",
    "\n",
    "hello-world         latest              fce289e99eb9        7 months ago        1.84kB\n",
    "\n",
    " ra  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List all the containers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker container ls --all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ra  docker container ls --all\n",
    "\n",
    "CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS                      PORTS               NAMES\n",
    "\n",
    "9eec5f49fd27        hello-world         \"/hello\"            36 minutes ago      Exited (0) 36 minutes ago                       clever_lichterman\n",
    "\n",
    "886424febc43        hello-world         \"/hello\"            25 hours ago        Exited (0) 25 hours ago                         optimistic_leakey\n",
    "\n",
    " ra  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "sudo docker images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> docker rmi 886424febc43"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Security considerations\n",
    "You may have noticed all the commands so far have defaulted to running as root (sudo).\n",
    "\n",
    "<font color=\"red\">**This is an unsafe default and should be changed**</font>.\n",
    "\n",
    "There have been documented cases in the wild where attackers were able to elevate their privileges on a server by exploiting this security flaw.\n",
    "\n",
    "Create a new group and add users to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "sudo groupadd docker\n",
    "\n",
    "sudo useradd ra\n",
    "\n",
    "sudo usermod -aG docker ra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now you can run Docker with restricted ('normal user') privileges.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Dockerfile\n",
    "There is a means to automatically assign features to your application. This is achieved using a `Dockerfile`. It is literally a textfile with this name with specifications on how to build the image, based on requirements and the application itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p docker_test\n",
    "cd docker_test/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edit and save the Dockerfile. This is literally a text-file conforming to the following format. \n",
    "\n",
    "Docker builds images in layers. \n",
    "\n",
    "We want to build a Python 3.7 app, so we'll make use of a pre-compiled base image, from the official list of Docker pre-built images:\n",
    "https://hub.docker.com/search/?q=&type=image&image_filter=official "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Use an official Python runtime as a parent image\r\n",
      "FROM python:3.7-stretch\r\n",
      "\r\n",
      "# Set the working directory to /app\r\n",
      "WORKDIR /app\r\n",
      "\r\n",
      "# Copy the current directory contents into the container at /app\r\n",
      "COPY . /app\r\n",
      "\r\n",
      "# Install any needed packages specified in requirements.txt\r\n",
      "RUN pip install --trusted-host pypi.python.org -r requirements.txt\r\n",
      "\r\n",
      "# Make port 80 available to the world outside this container\r\n",
      "EXPOSE 80\r\n",
      "\r\n",
      "# Define environment variable\r\n",
      "ENV NAME World\r\n",
      "\r\n",
      "# Run app.py when the container launches\r\n",
      "CMD [\"python\", \"app.py\"]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "! cat code/docker_test/Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edit your  `requirements.txt` in the same directory. \n",
    "\n",
    "Here, we'll just make use of NumPy, so it has one single line:\n",
    "\n",
    "> Numpy\n",
    "\n",
    "\n",
    "Pure poetry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you'll need to write your code in a format that is executable from a single source. The convention is to name the file `app.py`.\n",
    "\n",
    "I've written a small game where you fight a mythical beast known as a Grue, and you get to attack it by rolling a twenty-sided die."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Build your app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker build --tag=roll20 ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ra  docker_test  docker build --tag=roll20 .\n",
    "\n",
    "Sending build context to Docker daemon  13.82kB\n",
    "\n",
    "Step 1/7 : FROM python:3.7-stretch\n",
    "\n",
    "3.7-stretch: Pulling from library/python\n",
    "\n",
    "a4d8138d0f6b: Pull complete\n",
    "\n",
    "dbdc36973392: Pull complete\n",
    "\n",
    "f59d6d019dd5: Pull complete\n",
    "\n",
    "aaef3e026258: Pull complete\n",
    "\n",
    "6e454d3b6c28: Pull complete\n",
    "\n",
    "47c95b44ab24: Pull complete\n",
    "\n",
    "5570e9404146: Pull complete\n",
    "\n",
    "281654452bf7: Pull complete\n",
    "\n",
    "ea8e7ce389f6: Pull complete\n",
    "\n",
    "Digest: sha256:99a16ef43ba12811a369a2912d8c73b0ebc69aed55b327653185ba1330e3121c\n",
    "\n",
    "Status: Downloaded newer image for python:3.7-stretch\n",
    "\n",
    " ---> 46ccb963c04a\n",
    "\n",
    "Step 2/7 : WORKDIR /app\n",
    "\n",
    " ---> Running in 2d61c8c30d47\n",
    "\n",
    "Removing intermediate container 2d61c8c30d47\n",
    "\n",
    " ---> afe6111ba6db\n",
    "\n",
    "Step 3/7 : COPY . /app\n",
    "\n",
    " ---> 33de3c146ced\n",
    "\n",
    "Step 4/7 : RUN pip install --trusted-host pypi.python.org -r requirements.txt\n",
    "\n",
    " ---> Running in 67f6423f75ed\n",
    "\n",
    "Collecting Numpy (from -r requirements.txt (line 1))\n",
    "\n",
    "  Downloading https://files.pythonhosted.org/packages/05/4b/55cfbfd3e5e85016eeef9f21c0ec809d978706a0d60b62cc28aeec8c792f/numpy-1.17.0-cp37-cp37m-manylinux1_x86_64.whl (20.3MB)\n",
    "\n",
    "Installing collected packages: Numpy\n",
    "\n",
    "Successfully installed Numpy-1.17.0                                                                                                                                         #Removing intermediate container 67f6423f75ed\n",
    "\n",
    " ---> a377775d78d2                                                                                                                                                          #Step 5/7 : EXPOSE 80\n",
    "\n",
    " ---> Running in a47e882fff57\n",
    "\n",
    "Removing intermediate container a47e882fff57\n",
    "\n",
    " ---> 7ce058f2a24d\n",
    "\n",
    "Step 6/7 : ENV NAME World\n",
    "\n",
    " ---> Running in 94af2c3d890e\n",
    "\n",
    "Removing intermediate container 94af2c3d890e\n",
    "\n",
    " ---> 7e616d4dae80\n",
    "\n",
    "Step 7/7 : CMD [\"python\", \"app.py\"]\n",
    "\n",
    " ---> Running in f79a3cee87bc\n",
    "\n",
    "Removing intermediate container f79a3cee87bc\n",
    "\n",
    " ---> 399918acce75\n",
    "\n",
    "Successfully built 399918acce75\n",
    "\n",
    "Successfully tagged roll20:latest\n",
    "\n",
    " ra  docker_test  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Check your app was installed by checking your local Docker image registry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker image ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ra  docker_test  docker image ls\n",
    "\n",
    "REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\n",
    "\n",
    "roll20              latest              399918acce75        2 minutes ago       1.05GB\n",
    "\n",
    "python              3.7-stretch         46ccb963c04a        4 days ago          941MB\n",
    "\n",
    "hello-world         latest              fce289e99eb9        7 months ago        1.84kB\n",
    "\n",
    " ra  docker_test  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker run roll20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run this with port settings with the -p flag too\n",
    " \n",
    "If you update just the app code, you can re-build the Docker image.\n",
    "This is not as resource-intensive as the initial build; only necessary changes are\n",
    "brought in. \n",
    "\n",
    "After updating `app.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker build --tag=roll20 ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ra  docker_test  docker build --tag=roll20 .\n",
    "\n",
    "Sending build context to Docker daemon  14.85kB\n",
    "\n",
    "Step 1/7 : FROM python:3.7-stretch\n",
    "\n",
    " ---> 46ccb963c04a\n",
    "\n",
    "Step 2/7 : WORKDIR /app\n",
    "\n",
    " ---> Using cache\n",
    "\n",
    " ---> afe6111ba6db\n",
    "\n",
    "Step 3/7 : COPY . /app\n",
    "\n",
    " ---> 045ec16d8ef9\n",
    "\n",
    "Step 4/7 : RUN pip install --trusted-host pypi.python.org -r requirements.txt\n",
    "\n",
    " ---> Running in 43e19094cefc\n",
    "\n",
    "Collecting Numpy (from -r requirements.txt (line 1))\n",
    "\n",
    "  Downloading https://files.pythonhosted.org/packages/05/4b/55cfbfd3e5e85016eeef9f21c0ec809d978706a0d60b62cc28aeec8c792f/numpy-1.17.0-cp37-cp37m-manylinux1_x86_64.whl (20.3MB)\n",
    "\n",
    "Installing collected packages: Numpy\n",
    "\n",
    "Successfully installed Numpy-1.17.0\n",
    "\n",
    "Removing intermediate container 43e19094cefc\n",
    "\n",
    " ---> 163207aac796\n",
    "\n",
    "Step 5/7 : EXPOSE 80\n",
    "\n",
    " ---> Running in 8aa0e71c200a\n",
    "\n",
    "Removing intermediate container 8aa0e71c200a\n",
    "\n",
    " ---> b050fbb7e37d\n",
    "\n",
    "Step 6/7 : ENV NAME World\n",
    "\n",
    " ---> Running in 106425262fb7\n",
    "\n",
    "Removing intermediate container 106425262fb7\n",
    "\n",
    " ---> 74f217a1d060\n",
    "\n",
    "Step 7/7 : CMD [\"python\", \"app.py\"]\n",
    "\n",
    " ---> Running in 016daabdcdbf\n",
    "\n",
    "Removing intermediate container 016daabdcdbf\n",
    "\n",
    " ---> ccdf3af1d563\n",
    "\n",
    "Successfully built ccdf3af1d563\n",
    "\n",
    "Successfully tagged roll20:latest\n",
    "\n",
    " ra  docker_test  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " You can get a lot of details about your image using `inspect`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker inspect roll20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ra  ⋯  notebooks  code  docker_test  docker inspect roll20\n",
    "\n",
    "[\n",
    "\n",
    "    {\n",
    "\n",
    "        \"Id\": \"sha256:ccdf3af1d5639c44a2b2237415c3d0eb8d3181f04b3d7297bc5a7a24ba3ac119\",\n",
    "\n",
    "        \"RepoTags\": [\n",
    "\n",
    "            \"roll20:latest\"\n",
    "\n",
    "        ],\n",
    "\n",
    "        \"RepoDigests\": [],\n",
    "\n",
    "        \"Parent\": \"sha256:74f217a1d0607f53bc7ff0ded59c5260e3b6cdee6d7201bedfcde40bf9d50595\",\n",
    "\n",
    "        \"Comment\": \"\",\n",
    "\n",
    "        \"Created\": \"2019-08-03T22:21:30.841261217Z\",\n",
    "\n",
    "        \"Container\": \"016daabdcdbf44dd66aac37783f216ba034e25f5bc7592c43585337a88ab94c4\","
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "In a distributed application, different pieces of the app are called “services”. For example, if you imagine a video sharing site, it probably includes a service for storing application data in a database, a service for video transcoding in the background after a user uploads something, a service for the front-end, and so on.\n",
    "\n",
    "Services are really just “containers in production.” A service only runs one image, but it codifies the way that image runs—what ports it should use, how many replicas of the container should run so the service has the capacity it needs, and so on. Scaling a service changes the number of container instances running that piece of software, assigning more computing \n",
    " resources to the service in the process.\n",
    "\n",
    "Luckily it’s very easy to define, run, and scale services with the Docker platform -- just write a docker-compose.yml file.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize a Docker Swarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker swarm init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ra  docker_test  docker swarm init\n",
    "\n",
    "Swarm initialized: current node (rf2mpr85sxew8crlg4s5zv71s) is now a manager.\n",
    "\n",
    "\n",
    "\n",
    "To add a worker to this swarm, run the following command:\n",
    "\n",
    "\n",
    "\n",
    "    docker swarm join --token SWMTKN-1-33jpx3rgyhnm4z2yeiftw2lvdyclhqjqeaoyz7w2ysg4om5c76-1inpnveoah0zjd01gopt4n20o 10.0.2.15:2377\n",
    "\n",
    "\n",
    "\n",
    "To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions.\n",
    "\n",
    "ra  docker_test  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Deploy the app\n",
    " We have to call it something! Let's call this one `attack_the_grue`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker stack deploy -c docker-compose.yml attack_the_grue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ra  docker_test  docker stack deploy -c docker-compose.yml attack_the_grue\n",
    "\n",
    "Creating network attack_the_grue_default\n",
    "\n",
    "Creating service attack_the_grue_roll20\n",
    "\n",
    " ra  docker_test  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check all the services running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker service ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ra  docker_test  docker service ls\n",
    "\n",
    "ID                  NAME                     MODE                REPLICAS            IMAGE               PORTS\n",
    "\n",
    "uzxy32f944ye        attack_the_grue_roll20   replicated          0/5                 ra/roll20:latest                                                                       \n",
    "\n",
    "ra  docker_test  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker container ls -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show all tasks on a stack:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker stack ps attack_the_grue "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale up your app\n",
    "\n",
    "---\n",
    "\n",
    "You can scale the app by changing the replicas value in docker-compose.yml, saving the change, and re-running the docker stack deploy command:\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "open docker-compose.yml: no such file or directory\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'docker stack deploy -c docker-compose.yml attack_the_grue\\n'' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-80402898ce44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'docker stack deploy -c docker-compose.yml attack_the_grue\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2345\u001b[0m                 \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2346\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2347\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2348\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</home/ra/anaconda3/lib/python3.6/site-packages/decorator.py:decorator-gen-110>\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'docker stack deploy -c docker-compose.yml attack_the_grue\\n'' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "docker stack deploy -c docker-compose.yml attack_the_grue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tear down the app and the swarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker stack rm attack_the_grue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker swarm leave --force"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ra  docker_test  docker swarm leave --force\n",
    "\n",
    "Node left the swarm.\n",
    "\n",
    "ra  docker_test  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How easy was that? \n",
    "\n",
    "You can scale an application using this container model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Swarm clusters and the stack\n",
    "\n",
    "A _swarm_ is all the combined resources running your Docker instances. It's a great mental image. These instances need to be managed.\n",
    "Swarm managers take intructions on how to run this ensemble of containers. They act as administrators for the spun-up Docker images.\n",
    "\n",
    "This is the cluster version of the single-instance you have been running up until now.\n",
    "\n",
    "A _stack_ is all the services that share dependencies and can be co-ordinated together. This, in principle, can organize an entire application, although multiple stacks may also be required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run your Docker application on the cloud, you may need to open ports from your image to services on cloud machines. This is if your app requires communication to an SSH or web service, or to communicate with a database.\n",
    "\n",
    "Typical port numbers for each service are:\n",
    "\n",
    "\n",
    "| Service | Type  | Protocol | Port |\n",
    "| --- | --- | --- | --- |\n",
    "| Web         | HTTP  | TCP | 80 |\n",
    "| Visualizer  | HTTP  | TCP | 8080 |\n",
    "| Redis       | TCP   | TCP | 6379 |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More resources\n",
    "\n",
    " The Docker Cheatsheet website:\n",
    " https://dockercheatsheet.painlessdocker.com/\n",
    "\n",
    " On GitHub:\n",
    "https://github.com/wsargent/docker-cheat-sheet\n",
    "\n",
    " Docker's website:\n",
    "https://www.docker.com/get-started        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Here, we covered what goes into packaging a Python project, including the differences between a Python _module_, a _package_ and a _library_ (what was the difference?)\n",
    "\n",
    "We also looked at automation of Python scripts.\n",
    "\n",
    "Finally, we looked at how to build and deploy Python scripts rapidly, using the popular containerization framework Docker."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
